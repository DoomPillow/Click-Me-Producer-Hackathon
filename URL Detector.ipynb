{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7219839",
   "metadata": {},
   "source": [
    "# URL Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6daebb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "from PIL import Image, ImageEnhance, ImageOps, ImageDraw, ImageFont\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# CNN\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# OCR\n",
    "import pytesseract\n",
    "import re\n",
    "\n",
    "# Info\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda9589f",
   "metadata": {},
   "source": [
    "# Define necessary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e052566",
   "metadata": {},
   "source": [
    "<h3>split_video()</h3>\n",
    "\n",
    "Takes in a video and splits it into frames.\n",
    "\n",
    "<b>Parameters:</b>\n",
    "\n",
    "- file(str): Path to video file to split\n",
    "- increment(int): The number of frames the function should skip between each capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e4ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_video(file, increment):\n",
    "    \n",
    "    position = 0\n",
    "    current_iteration = 0\n",
    "    \n",
    "    if file.endswith('.mp4'):\n",
    "        # Load video\n",
    "        video_path = os.path.join(input_path, file)\n",
    "        capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "        # Get the total number of frames in the video + Create progress bar\n",
    "        total_frames = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        pbar = tqdm(total=total_frames // increment, desc=f'[1/3]Processing video: {file}', position=position)\n",
    "\n",
    "        # Loop through every nth frame in the video\n",
    "        frameNum = 0\n",
    "\n",
    "        while True:\n",
    "            # Skip frames that do not need to be read\n",
    "            if frameNum % increment != 0:\n",
    "                ret = capture.grab()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frameNum += 1\n",
    "                continue\n",
    "\n",
    "            # Read the next frame\n",
    "            ret, frame = capture.read()\n",
    "\n",
    "            # Exit if reached last frame\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Save to backgrounds directory\n",
    "            milis = (capture.get(cv2.CAP_PROP_POS_MSEC)) * 0.001\n",
    "            timestamp = str(timedelta(seconds=milis)).replace(':', '-')\n",
    "            \n",
    "            frame_path = f'{os.path.join(process_path, timestamp)}.jpg'\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "\n",
    "            # Increment frame\n",
    "            frameNum += 1\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix(frame=frameNum)\n",
    "\n",
    "        # Release capture\n",
    "        capture.release()\n",
    "        pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89ea7c0",
   "metadata": {},
   "source": [
    "<h3>clear()</h3>\n",
    "\n",
    "The clear function deletes every file in the process directory. This is to be used after the URL is already extracted to free space, as the frames are no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c284eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear():\n",
    "    \"\"\"\n",
    "    Remove all temporary files in the specified directory.\n",
    "    \"\"\"\n",
    "    for file in os.listdir(process_path):\n",
    "        os.remove(os.path.join(process_path, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e279cdff",
   "metadata": {},
   "source": [
    "<h3> preprocess_images() </h3>\n",
    "    \n",
    "preprocesses images for cnn use\n",
    "\n",
    "<b>Parameters:</b>\n",
    "\n",
    "- _dir(str): Path to input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa1b4ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess all images in dir\n",
    "def preprocess_images(_dir):\n",
    "    image_files = os.listdir(_dir) \n",
    "    images = []\n",
    "    for image_file in image_files:\n",
    "        img = image.load_img( os.path.join(_dir, image_file) , target_size=(224, 224))\n",
    "        img_array = image.img_to_array(img) \n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = tf.keras.applications.mobilenet.preprocess_input(img_array)\n",
    "        images.append(img_array)\n",
    "    return np.vstack(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a302f4",
   "metadata": {},
   "source": [
    "<h3> predict_url() </h3>\n",
    "\n",
    "Uses pytesseract to predict the text and bounding boxes of the url contained in the image if any.  \n",
    "\n",
    "<b>Parameters:</b>\n",
    "\n",
    "- img(str): Path to image file\n",
    "- spread(float): Number of pixels to add to bounding box coordinates for displaying URL text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7445110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_url(img, spread):\n",
    "    img = Image.open(img)\n",
    "    \n",
    "    ## Process the Image\n",
    "    # Greyscale\n",
    "    img = img.convert('L')\n",
    "\n",
    "    # Threshold\n",
    "    img = img.point( lambda p: 255 if p > 180 else 0)\n",
    "\n",
    "    ## Predict URL\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    # Predict bbox\n",
    "    word_box = pytesseract.image_to_boxes(img).split('\\n')\n",
    "    \n",
    "    # Remove non URL text\n",
    "    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    urls = url_pattern.findall(text)\n",
    "    \n",
    "    ## Bbox stuff\n",
    "    \n",
    "    # Find word\n",
    "    if len(urls) > 0:\n",
    "        url = urls[0]\n",
    "        url_box = None\n",
    "\n",
    "        score = 0\n",
    "        url_array = []\n",
    "        for box in word_box:\n",
    "            if score != len(url):\n",
    "                if box.split(' ')[0] == url[score]:\n",
    "                    score += 1\n",
    "                    url_array.append(box.split(' '))\n",
    "                else:\n",
    "                    score = 0\n",
    "                    url_array = []\n",
    "\n",
    "        # Find bounding box of full url\n",
    "        h = img.height\n",
    "\n",
    "        x1, y1, x2, y2 = int(url_array[0][1]) - spread, h - int(url_array[0][2]) - spread, int(url_array[-1][3]) + spread, h - int(url_array[-1][4]) + spread\n",
    "\n",
    "        return [urls, (x1, y1, x2, y2)]\n",
    "    else: return['null','null']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b315e9",
   "metadata": {},
   "source": [
    "<h3> grab_urls() </h3>\n",
    "\n",
    "Extracts URLs from overlayed frames of a video file and displays the URLs on the frames.  \n",
    "\n",
    "<b>Parameters:</b>\n",
    "- video (str): path to video file  \n",
    "- increment (int): number of skipped frames between extracted frames (default: 60)  \n",
    "- spread (float): number of pixels to add to bounding box coordinates for displaying URL text (default: 35)  \n",
    "- cleanup (bool): whether to remove temporary files created by function (default: True)  \n",
    "- uniqueonly (bool): whether to remove redundant entries (default: True)  \n",
    "- preview (bool): whether to display preview images with URLs and bounding boxes (default: False)  \n",
    "- output_path (str): path to save preview images (default: 'output') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87433084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_urls(video, increment=60, spread=35, cleanup=True, uniqueonly=True, preview=False, output_path='output'):\n",
    "    \n",
    "    assert os.path.isfile(os.path.join(input_path, video))\n",
    "    \n",
    "    # Split video into frames\n",
    "    split_video(video, increment)\n",
    "    \n",
    "    # Preprocess images for CNN use\n",
    "    preprocessed_images = preprocess_images(process_path)\n",
    "    \n",
    "    # Make predictions\n",
    "    print('[2/3]Predicting overlayed frames...')\n",
    "    predictions = model.predict(preprocessed_images)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Identify predicted overlayed frames\n",
    "    directory = os.listdir(process_path)\n",
    "    overlayed = [directory[i] for i, label in enumerate(predicted_labels) if label == 1]\n",
    "    \n",
    "    # Extract URLs\n",
    "    urls = []\n",
    "    bboxes = []\n",
    "    times = []\n",
    "    nulls = []\n",
    "    \n",
    "    print('[3/3]Predicting URLs...')\n",
    "    for img in overlayed:\n",
    "        # Predict URL\n",
    "        URL = predict_url(os.path.join(process_path, img), spread=spread)\n",
    "        if URL[0] != 'null':\n",
    "            if (URL[0] not in urls) or not uniqueonly:\n",
    "                urls.append(URL[0])\n",
    "                bboxes.append(URL[1])\n",
    "                times.append(img.replace('-', ':').replace('.jpg', ''))\n",
    "        else:\n",
    "            nulls.append(img.replace('-', ':').replace('.jpg', ''))\n",
    "    \n",
    "    # Display information\n",
    "    \n",
    "    #times = [timestamp.replace('-', ':').replace('.jpg', '') for timestamp in overlayed]\n",
    "    times_str = ' , '.join(times)\n",
    "    \n",
    "    print(f'\\n\\nFound {len(times)} overlayed frames at timestamps: {times_str}')\n",
    "    for url, bbox in zip(urls, bboxes):\n",
    "        print(url, bbox)\n",
    "        \n",
    "    # Display image\n",
    "    if preview:\n",
    "        font = ImageFont.truetype('arial.ttf', 27)\n",
    "        for img, url, bbox in zip(times, urls, bboxes):\n",
    "            prev = Image.open(os.path.join(process_path, f\"{img.replace(':', '-')}.jpg\"  )).copy()\n",
    "            draw = ImageDraw.Draw(prev)\n",
    "            draw.rectangle(bbox, outline=\"red\", width=5)\n",
    "            draw.text((bbox[0] + spread, bbox[1] - 35), str(url), font=font, fill='red')\n",
    "            prev.save(os.path.join(output_path, f\"{video.replace('.mp4', '')}  {img.replace(':', '-')}.jpg\"))\n",
    "    \n",
    "    # Remove temporary files if cleanup is enabled\n",
    "    if cleanup:\n",
    "        clear()\n",
    "        \n",
    "    return [times,urls,bboxes, nulls, '']\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c8aefad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_json(_json_):\n",
    "    print('\\n█════════════════════════════════════════════════█ JSON OUTPUT █════════════════════════════════════════════════█\\n')\n",
    "    for filename, data in _json_.items():\n",
    "        print('---------------------\\n',filename,'\\n---------------------\\n')\n",
    "\n",
    "        # Iterate over the keys in the data dictionary for the current file\n",
    "        for key, values in data.items():\n",
    "            print(key,':')\n",
    "\n",
    "            if key == 'nulls':\n",
    "                print(colored(' , '.join(values), 'red'),'\\n') if  len(values) > 0 else print(colored('none','green'),'\\n') \n",
    "\n",
    "            else:\n",
    "                print('   URL: ', ' , '.join(values['url']) )\n",
    "                print('   Coords: ', values['coords'] )\n",
    "                print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ba03aa",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88b0b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.styles import ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "\n",
    "from reportlab.platypus import Image as RLImage\n",
    "\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccfe62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(os.path.join('resources','URL_Grabber_model_v2.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a8b6a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure needed directories actually exists\n",
    "\n",
    "if os.path.isdir('input') is False:\n",
    "    os.mkdir('input')\n",
    "if os.path.isdir('process') is False:\n",
    "    os.mkdir('process')\n",
    "if os.path.isdir('output') is False:\n",
    "    os.mkdir('output')\n",
    "\n",
    "input_path = 'input'\n",
    "process_path = 'process'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "127f2cfe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/3]Processing video: 1665515252406.mp4: 76it [00:06, 11.17it/s, frame=4501]                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/3]Predicting overlayed frames...\n",
      "3/3 [==============================] - 3s 583ms/step\n",
      "[3/3]Predicting URLs...\n",
      "\n",
      "\n",
      "Found 3 overlayed frames at timestamps: 0:01:12 , 0:01:20 , 0:01:28\n",
      "['https://json-schema.org'] (-1, 632, 362, 688)\n",
      "['https://cuelang.org'] (-1, 632, 307, 689)\n",
      "['https://marshmallow.readthedocs.io/en/stable'] (-1, 632, 643, 689)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/3]Processing video: 1671575434239.mp4: 44it [00:03, 12.06it/s, frame=2581]                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/3]Predicting overlayed frames...\n",
      "2/2 [==============================] - 1s 351ms/step\n",
      "[3/3]Predicting URLs...\n",
      "\n",
      "\n",
      "Found 1 overlayed frames at timestamps: 0:01:20\n",
      "['https://github.com'] (0, 592, 301, 649)\n",
      "\n",
      "█════════════════════════════════════════════════█ JSON OUTPUT █════════════════════════════════════════════════█\n",
      "\n",
      "---------------------\n",
      " 1665515252406.mp4 \n",
      "---------------------\n",
      "\n",
      "nulls :\n",
      "\u001b[31m0:00:50 , 0:00:52 , 0:01:18 , 0:01:24 , 0:01:26 , 0:01:42 , 0:01:44 , 0:02:14 , 0:02:16\u001b[0m \n",
      "\n",
      "0:01:12 :\n",
      "   URL:  https://json-schema.org\n",
      "   Coords:  (-1, 632, 362, 688)\n",
      "\n",
      "0:01:20 :\n",
      "   URL:  https://cuelang.org\n",
      "   Coords:  (-1, 632, 307, 689)\n",
      "\n",
      "0:01:28 :\n",
      "   URL:  https://marshmallow.readthedocs.io/en/stable\n",
      "   Coords:  (-1, 632, 643, 689)\n",
      "\n",
      "---------------------\n",
      " 1671575434239.mp4 \n",
      "---------------------\n",
      "\n",
      "nulls :\n",
      "\u001b[32mnone\u001b[0m \n",
      "\n",
      "0:01:20 :\n",
      "   URL:  https://github.com\n",
      "   Coords:  (0, 592, 301, 649)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create dict\n",
    "keyeddata = {}\n",
    "for video in os.listdir(input_path):\n",
    "\n",
    "    urldata = grab_urls(video, preview=True)\n",
    "    \n",
    "    # Create entry for video + add nulls\n",
    "    keyeddata[video] = {}\n",
    "    keyeddata[video]['nulls'] = urldata[3]\n",
    "    \n",
    "    # Add info for each respective timestamp\n",
    "    for i in range(len(urldata[0])):\n",
    "        keyeddata[video][urldata[0][i]] = dict(zip(['url','coords'],[urldata[1][i],urldata[2][i]]))\n",
    "\n",
    "# Save JSON\n",
    "with open(\"output/url data.json\", \"w\") as output:\n",
    "    json.dump(keyeddata, output)\n",
    "    \n",
    "# Print it out in a way humans can read without sprouting a brain tumor\n",
    "print_json(keyeddata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bddf14",
   "metadata": {},
   "source": [
    "# Inspect URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3448453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_url(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d39e14fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    title = soup.title.string.strip()\n",
    "    simplified_title = title.split(':')[0].split(' - ')[0].split(' | ')[0].split(' – ')[0]\n",
    "    return simplified_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fde10007",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/url data.json', 'r') as data:\n",
    "    json_data = json.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0df4e80d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a total of \u001b[32m4\u001b[0m working, and \u001b[31m0\u001b[0m broken:\n",
      "\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "working = []\n",
    "broken = []\n",
    "for filename, data in json_data.items():\n",
    "    #print(f'{filename}:')\n",
    "    for key, values in data.items():\n",
    "        if key != 'nulls':\n",
    "            for url in values['url']:\n",
    "                status = check_url(url)\n",
    "                #print(f\"   {colored('works!', 'green') if check_url(url) else colored('broken', 'red')}  {url}\")\n",
    "                \n",
    "                (working if status else broken).append(url)\n",
    "                \n",
    "print('found a total of', colored(len(working), 'green'),'working, and', colored(len(broken), 'red'),'broken:\\n\\n',broken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca24262",
   "metadata": {},
   "source": [
    "# Create PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f26f0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSP-regular resources\\fonts\\SourceSansPro-Light.ttf\n",
      "SSP-bold resources\\fonts\\SourceSansPro-Semibold.ttf\n",
      "SSP-italic resources\\fonts\\SourceSansPro-Lightit.ttf\n",
      "SSP-bolditalic resources\\fonts\\SourceSansPro-Semiboldit.ttf\n"
     ]
    }
   ],
   "source": [
    "# Define font paths\n",
    "folder = os.path.join('resources','fonts')\n",
    "fontFiles = [{'SSP-regular': os.path.join(folder, 'SourceSansPro-Light.ttf')},\n",
    "             {'SSP-bold': os.path.join(folder, 'SourceSansPro-Semibold.ttf')},\n",
    "             {'SSP-italic': os.path.join(folder, 'SourceSansPro-Lightit.ttf')},\n",
    "             {'SSP-bolditalic': os.path.join(folder, 'SourceSansPro-Semiboldit.ttf')}]\n",
    "\n",
    "# Register fonts\n",
    "for fontFile in fontFiles:\n",
    "    (fontName, filePath), = fontFile.items()\n",
    "    print(fontName, filePath)\n",
    "    pdfmetrics.registerFont(TTFont(fontName, filePath))\n",
    "    \n",
    "# Create styles\n",
    "styles = {\n",
    "    'default': ParagraphStyle(\n",
    "        'default',\n",
    "        fontName='SSP-regular',\n",
    "        fontSize=12,\n",
    "        leading=14,\n",
    "    )\n",
    "}\n",
    "\n",
    "# Create tags for easy use\n",
    "tags = {\n",
    "    'b': \"<font name='SSP-bold'>\",\n",
    "    'i': \"<font name='SSP-italic'>\",\n",
    "    'bi': \"<font name='SSP-bolditalic'>\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0f35d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = SimpleDocTemplate(\"output/links.pdf\", pagesize=letter, leftMargin=45)\n",
    "\n",
    "DOCUMENT = []\n",
    "\n",
    "# add the image to the document\n",
    "header_image = Image(\"resources/images/demo header.png\", width=letter[0], height=letter[1]*0.16 )\n",
    "header_image._offs_y = 80\n",
    "header_image._offs_x = 10\n",
    "DOCUMENT.append(header_image)\n",
    "DOCUMENT.append(Spacer(0, -60))\n",
    "\n",
    "# create a hyperlink\n",
    "for filename, data in json_data.items():\n",
    "    for key, values in data.items():\n",
    "        if key != 'nulls':\n",
    "            url = values['url'][0]\n",
    "            \n",
    "            text = f\"{tags['b']}{get_title_from_url(url)} –</font> <a href='{url}'> {url} </a> <br /><br />\"\n",
    "            DOCUMENT.append(Paragraph(text, styles['default']))\n",
    "\n",
    "doc.build(DOCUMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6b0235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1970415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
